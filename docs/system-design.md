# bft-maker — System Design

## Stack

Vanilla TypeScript. No framework. No runtime dependencies beyond Node. Output is numbered SQL files and a shell runner. DuckDB is the primary SQL dialect. Spark SQL is the secondary dialect for scale-out.

---

## Project Structure

```
bft-maker/
├── src/
│   ├── manifest/
│   │   ├── types.ts              # Manifest schema (TypeScript interfaces)
│   │   ├── validate.ts           # Manifest validation and consistency checks
│   │   ├── estimate.ts           # Row count and cost estimators
│   │   ├── graph.ts              # Graph utilities (connected components)
│   │   └── yaml.ts               # YAML parse/serialize/load/save
│   │
│   ├── codegen/                  # (not yet implemented)
│   │   ├── planner.ts            # Manifest → ordered build plan
│   │   ├── sql/
│   │   │   ├── allocation.ts     # Allocation strategy template
│   │   │   ├── elimination.ts    # Elimination strategy template
│   │   │   ├── reserve.ts        # Reserve strategy template
│   │   │   ├── sum-over-sum.ts   # Sum/Sum strategy template
│   │   │   ├── join.ts           # Final join assembly
│   │   │   └── validation.ts     # Test query generator
│   │   ├── emit.ts               # Writes numbered .sql files + run.sh
│   │   └── dialects/
│   │       ├── duckdb.ts         # DuckDB dialect (primary)
│   │       └── spark.ts          # Spark SQL dialect (scale-out)
│   │
│   └── cli/
│       └── index.ts              # CLI entry point
│
├── test/
│   └── manifest/                 # Unit tests for validation and estimation
│
├── data/                         # Reference datasets and manifests
│   ├── northwind/                # Manifest for Northwind (data exists already)
│   ├── university/               # Synthetic university data + manifest
│   └── university-ops/           # Shared-dimension example (facilities + admissions)
│
├── docs/
│   ├── spec.md                   # What bft-maker does and how manifests work
│   └── system-design.md          # This file
│
├── dist/                         # Compiled output
├── tsconfig.json
└── package.json                  # devDependencies only: typescript, js-yaml
```

---

## Module Boundaries

Three independent layers. Each depends only on the manifest types. No layer imports from another layer.

```
┌────────────┐      ┌────────────┐
│  Validator  │─────▶│  Manifest  │◀─────┌────────────┐
│  (validate +│      │  (types)   │      │  Code Gen  │
│   estimate) │      └────────────┘      │  (planner + │
└────────────┘                           │   templates)│
                                         └────────────┘
```

The manifest is a plain object conforming to `types.ts`. It can be written by hand, produced by an LLM conversation, or generated by any tool. The code generator doesn't know or care which.

---

## Manifest Schema

The manifest is the contract. Everything downstream is mechanical. The TypeScript interfaces in `types.ts` are the source of truth; YAML serialization is just for human readability and version control.

```typescript
type Strategy = "reserve" | "elimination" | "allocation" | "sum_over_sum";

interface Manifest {
  entities: Entity[];
  relationships: Relationship[];
  propagations: MetricPropagation[];
  bft_tables: BftTable[];
  placeholder_labels?: PlaceholderLabels;
}

interface Entity {
  name: string;
  role: "leaf" | "bridge";
  detail: boolean;               // does this entity contribute rows?
  estimated_rows: number;
  metrics: MetricDef[];
}

interface MetricDef {
  name: string;
  type: "currency" | "integer" | "float" | "rating" | "percentage";
  nature: "additive" | "non-additive";
}

/** Relationships are undirected — they describe what joins exist. */
interface Relationship {
  name: string;
  between: [string, string];
  type: "many-to-many" | "many-to-one";
  estimated_links: number;
  weight_column?: string;        // e.g., "assignment_share"
}

/**
 * Defines how a metric propagates from its home entity to foreign entities.
 * Direction is implicit: always outward from the metric's home entity.
 * Metrics not listed here default to reserve (no propagation needed).
 */
interface MetricPropagation {
  metric: string;                // metric name (home entity is known)
  path: PropagationEdge[];       // ordered edges from home outward
}

/**
 * A single hop in a metric's propagation path.
 */
interface PropagationEdge {
  relationship: string;          // which relationship to traverse
  target_entity: string;         // which entity this edge reaches
  strategy: Strategy;            // what happens when crossing this edge
  weight?: string;               // for allocation/sum_over_sum: weight mechanism
}

/**
 * A BFT table. The entities list declares the grain —
 * what dimensions each row represents.
 */
interface BftTable {
  name: string;
  entities: string[];            // declares the grain (which entities form the row)
  metrics: string[];             // which metrics to include
}

/**
 * Labels for placeholder values in entity columns. When a metric's value
 * appears on a row that isn't about a specific foreign entity, the foreign
 * entity column shows this label. Both default to "<Unallocated>".
 */
interface PlaceholderLabels {
  reserve?: string;              // default: "<Unallocated>"
  elimination?: string;          // default: "<Unallocated>"
}
```

### Key Design Decisions

**Per-metric propagation paths replace metric clusters.** The old schema grouped metrics into clusters with traversal rules per cluster. The new schema defines propagation per-metric. Each metric has a path describing how it spreads from its home entity outward. Entities not in the path default to reserve.

**Grain is declared explicitly.** The table's `entities` list determines the grain — which dimensions each row represents. Propagation paths describe what metrics mean on foreign rows (how a metric's value spreads across entity boundaries), not which entities are in the grain.

**Relationships are undirected.** Relationships describe what joins exist. Direction comes from each metric's propagation path — always outward from the metric's home entity.

**Reserve is the default.** Any entity not mentioned in a metric's propagation path gets reserve treatment for that metric. Only non-reserve propagation needs to be declared.

---

## Cost Estimator

Row estimation is deterministic from Phase A cardinalities and propagation paths. The formulas live in `estimate.ts`.

### Row estimation for a set of grain entities

```typescript
function estimateRows(
  entities: Entity[],
  relationships: Relationship[],
  grainEntities: string[]
): RowEstimate;
```

Rules:
- Single entity with detail: `entity.estimated_rows`
- One M-M bridge: `relationship.estimated_links`
- Two M-M bridges sharing a bridge entity: `links₁ × (links₂ / bridge.estimated_rows)`
- Disconnected entities (no M-M connecting them): sum of row counts (sparse union)
- Placeholder rows: `entity.estimated_rows` per entity with reserve or elimination strategy metrics (rows where a foreign entity column shows a placeholder label)

### Table-level estimation with independent chains

```typescript
function estimateTableRows(manifest: Manifest, table: BftTable): RowEstimate;
```

`estimateTableRows` takes the table's declared grain entities and is aware of propagation paths. It detects **independent chains**. Each metric's propagation path defines a chain of entities (home + targets). When no single metric spans two chains, the codegen emits UNION ALL — not a cross product. The estimation reflects this:

- Each metric's chain: `{home_entity} ∪ {target entities in path}`
- Subset chains are absorbed by larger chains (their rows ride along)
- Independent chains (no metric spans both) are summed, not multiplied

Example: Building → Month (60 links) and Program → Month (36 links), no metric spanning Building-to-Program. Estimate: 60 + 36 = 96 rows. Not Building × Month × Program = 180.

---

## Code Generator

### Build Planner

`planner.ts` reads a complete manifest and produces an ordered list of build steps:

```typescript
interface BuildStep {
  order: number;
  filename: string;               // e.g., "01_base_enrollment.sql"
  description: string;
  depends_on: string[];           // filenames of prior steps
  type: "join" | "allocation" | "elimination" | "reserve" | "sum_over_sum" | "final";
}

function plan(manifest: Manifest): BuildStep[];
```

The ordering logic:
1. Base joins that establish the grain (one per BFT)
2. Strategy transformations (one per metric-strategy pair, parallelizable)
3. Final assembly join (combines all strategy outputs into the BFT)
4. Validation queries

### SQL Templates

Each strategy module exports a single function:

```typescript
// allocation.ts
function emitAllocation(metric: ResolvedMetric, table: BftTable, dialect: Dialect): string;

// elimination.ts
function emitElimination(metric: ResolvedMetric, table: BftTable, dialect: Dialect): string;

// reserve.ts
function emitReserve(metric: ResolvedMetric, table: BftTable, dialect: Dialect): string;

// sum-over-sum.ts
function emitSumOverSum(metric: ResolvedMetric, table: BftTable, dialect: Dialect): string;
```

Each returns a complete, executable SQL statement. No Jinja. No templating language. String interpolation from the manifest is the template engine.

```typescript
type Dialect = "duckdb" | "spark";
```

The dialect differences for the operations bft-maker uses (window functions, CTEs, aggregations, UNION ALL) are minimal. The dialect layer handles syntax variations like `CREATE OR REPLACE TABLE` vs `CREATE TABLE IF NOT EXISTS` and minor type casting differences.

### Validation Generator

`validation.ts` reads the manifest and emits one SQL query per assertion. Each query returns zero rows on success.

```typescript
function emitValidation(table: BftTable): ValidationQuery[];

interface ValidationQuery {
  name: string;                   // e.g., "allocation_sum_check_tuition_paid"
  description: string;
  sql: string;                    // returns rows only on failure
  severity: "error" | "warning"; // warnings for row count tolerance
}
```

### Output

`emit.ts` writes everything to a directory:

```
output/
├── 01_base_enrollment_join.sql
├── 02_allocate_tuition_paid.sql
├── 03_allocate_salary.sql
├── 04_eliminate_class_budget.sql
├── 05_reserve_overhead.sql
├── 06_sum_over_sum_satisfaction.sql
├── 07_final_assembly.sql
├── 08_validate.sql
├── run.sh
└── manifest.yaml                 # the manifest that produced this output
```

`run.sh` executes each file in order using DuckDB CLI:

```bash
#!/bin/bash
set -e
DB=${1:?"Usage: run.sh <database_path>"}
for f in [0-9]*.sql; do
  echo "Running $f..."
  duckdb "$DB" < "$f"
done
echo "All steps complete."
```

---

## CLI

The CLI reads a YAML manifest and writes output files:

```bash
npx bft-maker generate --manifest manifest.yaml --dialect duckdb --output ./sql/
npx bft-maker generate --manifest manifest.yaml --dialect spark --output ./sql/
npx bft-maker validate --manifest manifest.yaml
```

`validate` runs the manifest through the validator without generating code. `generate` validates first, then produces SQL.

---

## Testing Strategy

### Unit Tests (Node built-in test runner)

Pure function inputs and outputs. No SQL execution.

- `test/manifest/validate.test.ts`: feeds invalid manifests, asserts every inconsistency is caught (missing relationship references, disconnected paths, cycles, non-additive strategy constraints). Also validates all reference manifests.
- `test/manifest/estimate.test.ts`: known cardinalities in, expected row counts out. Tests independent chain detection, subset absorption, UNION ALL vs cross product behavior.
- `test/manifest/yaml.test.ts`: YAML round-trip (serialize → parse → compare), structural parsing.

### Reference Manifests

The `data/` directory contains manifests exercising different patterns:

- **university**: Students, Classes, Professors — multi-hop allocation, elimination, sum_over_sum
- **northwind**: Orders, Products — allocation by quantity, sum_over_sum for price
- **university-ops**: Facilities + Admissions sharing Month — shared-dimension alignment, independent chains, UNION ALL estimation

### Integration Tests (planned)

Once codegen is implemented:
1. Feed manifest to code generator
2. Execute SQL against DuckDB with synthetic data
3. Assert validation queries return zero rows
4. Assert `SUM` of allocated metrics equals `SUM` of originals

---

## What This Design Does Not Include

Things that are explicitly out of scope for v1:

- **A wizard UI.** The manifest is built through conversation (with an LLM or a colleague), not through a web form.
- **User authentication or multi-tenancy.** This is a local tool. Manifests are files.
- **A database for storing manifests.** The filesystem is the database. Git is the version history.
- **Source data profiling or introspection.** The user provides cardinalities. The engine trusts them.
- **BI tool integration.** The output is flat SQL tables. BI tools connect to them through their normal database connectors.
- **Incremental/streaming updates.** The generated SQL does full rebuilds.
- **Multiple SQL dialects beyond DuckDB and Spark SQL.** Two is enough. Others can be added later if needed.
